\subsection{User-defined functions}\label{user-defined-function-section}

A user-defined function must extend \verb|blog.model.AbstractFunctionInterp|
and provide a constructor that takes a single \verb|List| argument. When
compiling the class defining the user-defined function, you must add the \bl
JAR file to the class path.

Here is an example user-defined function computing the logarithm in base 10 of
a number:

\begin{minted}{java}
package my_package;

import java.util.List;

import blog.model.AbstractFunctionInterp;

public class Log10Interp extends AbstractFunctionInterp {
  public Log10Interp(List args) {
  }

  public Object getValue(List args) {
    final double value = ((Number) args.get(0)).doubleValue();
    return Math.log10(value);
  }
}
\end{minted}

To use this function from a model, declare it like this:

\begin{blogcode}
fixed Real log10(Real val) = my_package.Log10Interp();
\end{blogcode}

Then \verb|log10| can be used just like any other fixed function, e.g.
\verb|query log10(100.0)|.

Make sure \verb|my_package| is on the class path. If you get an error like "No
definition found for non-random function log10", you most likely have a
class-path problem. If \verb|my_package| is in the current working directory,
you need not do anything. Otherwise, if \verb|my_package| lives at
\verb|/some/absolute/path/my_package|, launch \bl with an environment variable:
{\tt CLASSPATH=/some/absolute/path blog model.blog}.

For more advanced examples of user-defined functions, see
\verb|blog.distrib.ListInterp| and \verb|blog.distrib.TabularInterp|.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{User-defined distributions}\label{user-defined-distribution-section}

Probability distributions are implemented in Java.  Distribution classes should implement the interface \verb|blog.distrib.CondProbDistrib|. 
By default, the \bl engine will look up distribution classes in the package \verb|blog.distrib|. In addition, it will look up distribution classes under the default empty package. 

Below is one example of a uniform distribution on Integers.
\begin{minted}{java}
package blog.distrib;

import blog.common.Util;

public class UniformInt implements CondProbDistrib {

  /**
   * set parameters for UniformInt
   * distribution
   * 
   * @param params
   *          An array of [Integer, Integer]
   *          <ul>
   *          <li>params[0]: <code>lower</code> (Integer)</li>
   *          <li>params[1]: <code>upper</code> (Integer)</li>
   *          </ul>
   * 
   * @see blog.distrib.CondProbDistrib#setParams(java.util.List)
   */
  @Override
  public void setParams(Object[] params) {
    if (params.length != 2) {
      throw new IllegalArgumentException("expected two parameters");
    }
    setParams((Integer) params[0], (Integer) params[1]);
  }

  /**
   * For a non-null value of method parameter lower, sets the
   * distribution parameter <code>lower</code> to method 
   * parameter lower. Similarly for <code>upper</code>. 
   * Then checks to see if assignment of parameters is legal. 
   * In other words, an assignment of parameters is legal
   * if <code>lower <= upper</code>.
   * 
   * @param lower
   *          parameter <code>lower</code>
   * @param upper
   *          parameter <code>upper</code>
   */
  public void setParams(Integer lower, Integer upper) {
    if (lower != null) {
      this.lower = lower;
      this.hasLower = true;
    }
    if (upper != null) {
      this.upper = upper;
      this.hasUpper = true;
    }
    if (this.hasLower && this.hasUpper) {
      if (this.lower > this.upper) {
        throw new IllegalArgumentException(
            "UniformInt distribution requires that lower <= upper");
      }
      this.prob = 1.0 / (this.upper - this.lower + 1);
      this.logProb = Math.log(this.prob);
    }
  }

  private void checkHasParams() {
    if (!this.hasLower) {
      throw new IllegalArgumentException("parameter lower not provided");
    }
    if (!this.hasUpper) {
      throw new IllegalArgumentException("parameter upper not provided");
    }
  }

  /*
   * (non-Javadoc)
   * 
   * @see blog.distrib.CondProbDistrib#getProb(java.lang.Object)
   */
  @Override
  public double getProb(Object value) {
    return getProb(((Integer) value).intValue());
  }

  /**
   * Returns the probability of the UniformInt distribution having 
   * outcome <code>value</code>.
   */
  public double getProb(int value) {
    checkHasParams();
    return (value >= lower) && (value <= upper) ? prob : 0;
  }

  /*
   * (non-Javadoc)
   * 
   * @see blog.distrib.CondProbDistrib#getLogProb(java.lang.Object)
   */
  @Override
  public double getLogProb(Object value) {
    return getLogProb(((Integer) value).intValue());
  }

  /**
   * Returns the log probability of the UniformInt distribution having outcome
   * <code>value</code>.
   */
  public double getLogProb(int value) {
    checkHasParams();
    return ((value >= lower) && (value <= upper)) ? logProb
        : Double.NEGATIVE_INFINITY;
  }

  /*
   * (non-Javadoc)
   * 
   * @see blog.distrib.CondProbDistrib#sampleVal()
   */
  @Override
  public Object sampleVal() {
    return sample_value();
  }

  public int sample_value() {
    checkHasParams();
    return lower + Util.randInt(upper - lower + 1);
  }

  @Override
  public String toString() {
    return getClass().getName();
  }

  /** Parameter <code>lower</code>. */
  private int lower;
  /** Flag indicating whether <code>lower</code> has been set. */
  private boolean hasLower;
  /** Parameter <code>upper</code>. */
  private int upper;
  /** Flag indicating whether <code>upper</code> has been set. */
  private boolean hasUpper;
  /**
   * The probability of an outcome between <code>lower</code> and
   * <code>upper</code> inclusive.
   */
  private double prob;
  /**
   * The log probability of an outcome between <code>lower</code> and
   * <code>upper</code> inclusive.
   */
  private double logProb;
}
\end{minted}


\section{Comprehensive examples}\label{example-section}

\subsection{Burglary}
The following example was due initially to Judea Pearl:
the alarm in a house goes off in response to a burglary or an earthquake,
but is somewhat unreliable. We might write the following model:
\begin{blogcode}
type House;

distinct House Maryhouse, Johnhouse, Cathyhouse, Rogerhouse;

random Boolean Burglary(House h) ~ BooleanDistrib(0.003);
random Boolean Earthquake ~ BooleanDistrib(0.002);
random Boolean Alarm(House h) ~ 
  case [Burglary(h), Earthquake] in {
    [false, false] -> BooleanDistrib(0.01),
    [false, true]  -> BooleanDistrib(0.40),
    [true, false]  -> BooleanDistrib(0.80),
    [true, true ]  -> BooleanDistrib(0.90)
  };

obs Alarm(Maryhouse) = true;
obs Alarm(Johnhouse) = true;
obs Alarm(Cathyhouse) = true;
obs Alarm(Rogerhouse) = false;

query Earthquake;
\end{blogcode}

\bl inference engine will produce the following likelihood of earthquake.
\begin{verbatim}
Number of samples: 10000
Distribution of values for Earthquake
	true	0.967140181036552
	false	0.03285981896344725
\end{verbatim}


\subsection{A hidden Markov model for genetic sequences}
\begin{example}[Hidden Markov models]
The following represents a hidden Markov model for genetic sequences with four states and four output symbols. The state at each time step transitions to another with respect to a conditional distribution specified by a TabularCPD. 
Each state at each time step emits an observation with respect to another CPD. After making a few observations, we can query the states for each time step.
\end{example}

\begin{blogcode}
type State;
distinct State A, C, G, T;

type Output;
distinct Output ResultA, ResultC, ResultG, ResultT;

random State S(Timestep t) ~
  if t == @0 then 
    Categorical({A -> 0.3, C -> 0.2, G -> 0.1, T -> 0.4})
  else case S(prev(t)) in {
    A -> Categorical({A -> 0.1, C -> 0.3, G -> 0.3, T -> 0.3}),
    C -> Categorical({A -> 0.3, C -> 0.1, G -> 0.3, T -> 0.3}),
    G -> Categorical({A -> 0.3, C -> 0.3, G -> 0.1, T -> 0.3}),
    T -> Categorical({A -> 0.3, C -> 0.3, G -> 0.3, T -> 0.1})
  };

random Output O(Timestep t) ~ 
  case S(t) in {
    A -> Categorical({
      ResultA -> 0.85, ResultC -> 0.05, 
      ResultG -> 0.05, ResultT -> 0.05}),
    C -> Categorical({
      ResultA -> 0.05, ResultC -> 0.85, 
      ResultG -> 0.05, ResultT -> 0.05}),
    G -> Categorical({
      ResultA -> 0.05, ResultC -> 0.05, 
      ResultG -> 0.85, ResultT -> 0.05}),
    T -> Categorical({
      ResultA -> 0.05, ResultC -> 0.05, 
      ResultG -> 0.05, ResultT -> 0.85})
  };

/* Evidence for the Hidden Markov Model.
 */

obs O(@0) = ResultC;
obs O(@1) = ResultA;
obs O(@2) = ResultA;
obs O(@3) = ResultA;
obs O(@4) = ResultG;

/* Queries for the Hiddem Markov Model, given the evidence.  
 * Note that we can query S(5) even though our observations only 
 * went up to time 4.
 */

query S(@0);
query S(@1);
query S(@2);
query S(@3);
query S(@4);
query S(@5);
\end{blogcode}

\bl will generate the following results using the particle filtering algorithm. 
\begin{verbatim}
Distribution of values for S(@0)
	C	0.8128524436090175
	T	0.09473684210526356
	A	0.06905545112781902
	G	0.023355263157894345
Distribution of values for S(@1)
	A	0.8700181159420364
	G	0.05365942028985556
	T	0.05143115942029019
	C	0.024891304347826236
Distribution of values for S(@2)
	A	0.7075761624799592
	C	0.09974612506680965
	G	0.0965058792089793
	T	0.0961718332442546
Distribution of values for S(@3)
	A	0.7633727477477481
	C	0.08085585585585582
	G	0.07908220720720713
	T	0.07668918918918921
Distribution of values for S(@4)
	G	0.8739530096536214
	C	0.050912123793299964
	T	0.05014906303236865
	A	0.02498580352072714
Distribution of values for S(@5)
	A	0.2989778534923363
	C	0.2949673480976736
	T	0.2767248722316938
	G	0.12932992617830938
\end{verbatim}

